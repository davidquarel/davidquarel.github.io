---
layout: post-custom
title: Dumping ground for benchmarks on GPUs 
date: 2024-10-01
tags:
published: true
---


I don't trust the magic numbers in the datasheets. 
Script just matmul's a bunch of matrices with random numbers of given size and precision.

<details>
<summary><strong>NVIDIA RTX A4000</strong></summary>

<table>
<thead>
<tr>
<th>Size</th>
<th>Precision</th>
<th>TFLOPs</th>
</tr>
</thead>
<tbody>
<tr><td>1024</td><td>FP32</td><td>9.70 ± 0.19</td></tr>
<tr><td>1024</td><td>FP32+TF32</td><td>18.45 ± 0.18</td></tr>
<tr><td>1024</td><td>FP16</td><td>35.59 ± 1.80</td></tr>
<tr><td>1024</td><td>FP16+TF32</td><td>37.56 ± 0.62</td></tr>
<tr><td>1024</td><td>FP16_REDUCED</td><td>38.20 ± 0.18</td></tr>
<tr><td>1024</td><td>BF16</td><td>34.71 ± 1.62</td></tr>
<tr><td>1024</td><td>BF16+TF32</td><td>36.17 ± 0.29</td></tr>
<tr><td>2048</td><td>FP32</td><td>11.41 ± 0.10</td></tr>
<tr><td>2048</td><td>FP32+TF32</td><td>29.47 ± 0.61</td></tr>
<tr><td>2048</td><td>FP16</td><td>57.91 ± 0.21</td></tr>
<tr><td>2048</td><td>FP16+TF32</td><td>54.99 ± 0.05</td></tr>
<tr><td>2048</td><td>FP16_REDUCED</td><td>54.89 ± 0.11</td></tr>
<tr><td>2048</td><td>BF16</td><td>55.04 ± 0.10</td></tr>
<tr><td>2048</td><td>BF16+TF32</td><td>55.12 ± 0.05</td></tr>
<tr><td>4096</td><td>FP32</td><td>9.07 ± 0.35</td></tr>
<tr><td>4096</td><td>FP32+TF32</td><td>30.33 ± 0.22</td></tr>
<tr><td>4096</td><td>FP16</td><td>65.45 ± 0.03</td></tr>
<tr><td>4096</td><td>FP16+TF32</td><td>65.88 ± 0.31</td></tr>
<tr><td>4096</td><td>FP16_REDUCED</td><td>63.56 ± 0.10</td></tr>
<tr><td>4096</td><td>BF16</td><td>65.33 ± 0.73</td></tr>
<tr><td>4096</td><td>BF16+TF32</td><td>64.83 ± 0.07</td></tr>
<tr><td>8192</td><td>FP32</td><td>11.84 ± 0.07</td></tr>
<tr><td>8192</td><td>FP32+TF32</td><td>30.27 ± 0.46</td></tr>
<tr><td>8192</td><td>FP16</td><td>60.78 ± 1.12</td></tr>
<tr><td>8192</td><td>FP16+TF32</td><td>61.47 ± 0.66</td></tr>
<tr><td>8192</td><td>FP16_REDUCED</td><td>61.00 ± 0.93</td></tr>
<tr><td>8192</td><td>BF16</td><td>59.32 ± 0.76</td></tr>
<tr><td>8192</td><td>BF16+TF32</td><td>57.89 ± 0.43</td></tr>
</tbody>
</table>

</details>

---

<details>
<summary><strong>NVIDIA GeForce RTX 3090</strong></summary>

<table>
<thead>
<tr>
<th>Size</th>
<th>Precision</th>
<th>TFLOPs</th>
</tr>
</thead>
<tbody>
<tr><td>1024</td><td>FP32</td><td>17.18 ± 0.50</td></tr>
<tr><td>1024</td><td>FP32+TF32</td><td>22.42 ± 0.80</td></tr>
<tr><td>1024</td><td>FP16</td><td>36.30 ± 1.90</td></tr>
<tr><td>1024</td><td>FP16+TF32</td><td>38.56 ± 0.61</td></tr>
<tr><td>1024</td><td>FP16_REDUCED</td><td>39.17 ± 0.13</td></tr>
<tr><td>1024</td><td>BF16</td><td>36.75 ± 2.05</td></tr>
<tr><td>1024</td><td>BF16+TF32</td><td>39.26 ± 0.15</td></tr>
<tr><td>2048</td><td>FP32</td><td>23.22 ± 0.47</td></tr>
<tr><td>2048</td><td>FP32+TF32</td><td>27.73 ± 0.59</td></tr>
<tr><td>2048</td><td>FP16</td><td>54.59 ± 0.12</td></tr>
<tr><td>2048</td><td>FP16+TF32</td><td>54.29 ± 0.04</td></tr>
<tr><td>2048</td><td>FP16_REDUCED</td><td>61.00 ± 0.08</td></tr>
<tr><td>2048</td><td>BF16</td><td>60.83 ± 0.08</td></tr>
<tr><td>2048</td><td>BF16+TF32</td><td>61.44 ± 0.27</td></tr>
<tr><td>4096</td><td>FP32</td><td>23.17 ± 0.65</td></tr>
<tr><td>4096</td><td>FP32+TF32</td><td>30.30 ± 0.47</td></tr>
<tr><td>4096</td><td>FP16</td><td>66.67 ± 0.50</td></tr>
<tr><td>4096</td><td>FP16+TF32</td><td>66.65 ± 0.07</td></tr>
<tr><td>4096</td><td>FP16_REDUCED</td><td>67.63 ± 0.01</td></tr>
<tr><td>4096</td><td>BF16</td><td>67.81 ± 0.11</td></tr>
<tr><td>4096</td><td>BF16+TF32</td><td>67.25 ± 0.11</td></tr>
<tr><td>8192</td><td>FP32</td><td>21.67 ± 0.18</td></tr>
<tr><td>8192</td><td>FP32+TF32</td><td>36.24 ± 0.27</td></tr>
<tr><td>8192</td><td>FP16</td><td>64.77 ± 1.16</td></tr>
<tr><td>8192</td><td>FP16+TF32</td><td>64.08 ± 0.35</td></tr>
<tr><td>8192</td><td>FP16_REDUCED</td><td>62.99 ± 0.60</td></tr>
<tr><td>8192</td><td>BF16</td><td>66.12 ± 0.31</td></tr>
<tr><td>8192</td><td>BF16+TF32</td><td>68.06 ± 0.43</td></tr>
</tbody>
</table>

</details>

---

<details>
<summary><strong>NVIDIA A40</strong></summary>

<table>
<thead>
<tr>
<th>Size</th>
<th>Precision</th>
<th>TFLOPs</th>
</tr>
</thead>
<tbody>
<tr><td>1024</td><td>FP32</td><td>14.79 ± 0.39</td></tr>
<tr><td>1024</td><td>FP32+TF32</td><td>32.12 ± 2.10</td></tr>
<tr><td>1024</td><td>FP16</td><td>49.54 ± 3.30</td></tr>
<tr><td>1024</td><td>FP16+TF32</td><td>53.04 ± 0.31</td></tr>
<tr><td>1024</td><td>FP16_REDUCED</td><td>52.95 ± 0.46</td></tr>
<tr><td>1024</td><td>BF16</td><td>47.15 ± 3.09</td></tr>
<tr><td>1024</td><td>BF16+TF32</td><td>44.51 ± 2.10</td></tr>
<tr><td>2048</td><td>FP32</td><td>20.29 ± 0.33</td></tr>
<tr><td>2048</td><td>FP32+TF32</td><td>44.98 ± 1.16</td></tr>
<tr><td>2048</td><td>FP16</td><td>93.13 ± 0.38</td></tr>
<tr><td>2048</td><td>FP16+TF32</td><td>90.48 ± 0.93</td></tr>
<tr><td>2048</td><td>FP16_REDUCED</td><td>88.76 ± 0.27</td></tr>
<tr><td>2048</td><td>BF16</td><td>88.96 ± 0.36</td></tr>
<tr><td>2048</td><td>BF16+TF32</td><td>89.25 ± 0.31</td></tr>
<tr><td>4096</td><td>FP32</td><td>22.98 ± 0.09</td></tr>
<tr><td>4096</td><td>FP32+TF32</td><td>55.94 ± 0.74</td></tr>
<tr><td>4096</td><td>FP16</td><td>111.99 ± 0.20</td></tr>
<tr><td>4096</td><td>FP16+TF32</td><td>114.65 ± 0.24</td></tr>
<tr><td>4096</td><td>FP16_REDUCED</td><td>114.80 ± 0.24</td></tr>
<tr><td>4096</td><td>BF16</td><td>114.89 ± 0.30</td></tr>
<tr><td>4096</td><td>BF16+TF32</td><td>114.90 ± 0.25</td></tr>
<tr><td>8192</td><td>FP32</td><td>22.83 ± 0.05</td></tr>
<tr><td>8192</td><td>FP32+TF32</td><td>59.55 ± 0.17</td></tr>
<tr><td>8192</td><td>FP16</td><td>79.35 ± 0.76</td></tr>
<tr><td>8192</td><td>FP16+TF32</td><td>79.39 ± 0.55</td></tr>
<tr><td>8192</td><td>FP16_REDUCED</td><td>79.54 ± 0.54</td></tr>
<tr><td>8192</td><td>BF16</td><td>113.85 ± 1.36</td></tr>
<tr><td>8192</td><td>BF16+TF32</td><td>112.31 ± 1.25</td></tr>
</tbody>
</table>

</details>

---

<details>
<summary><strong>NVIDIA A100 80GB PCIe</strong></summary>

<table>
<thead>
<tr>
<th>Size</th>
<th>Precision</th>
<th>TFLOPs</th>
</tr>
</thead>
<tbody>
<tr><td>1024</td><td>FP32</td><td>14.53 ± 0.22</td></tr>
<tr><td>1024</td><td>FP32+TF32</td><td>42.12 ± 3.65</td></tr>
<tr><td>1024</td><td>FP16</td><td>61.55 ± 4.43</td></tr>
<tr><td>1024</td><td>FP16+TF32</td><td>66.37 ± 0.67</td></tr>
<tr><td>1024</td><td>FP16_REDUCED</td><td>66.90 ± 0.65</td></tr>
<tr><td>1024</td><td>BF16</td><td>60.51 ± 5.38</td></tr>
<tr><td>1024</td><td>BF16+TF32</td><td>66.36 ± 0.55</td></tr>
<tr><td>2048</td><td>FP32</td><td>17.02 ± 0.25</td></tr>
<tr><td>2048</td><td>FP32+TF32</td><td>86.62 ± 4.41</td></tr>
<tr><td>2048</td><td>FP16</td><td>191.27 ± 2.31</td></tr>
<tr><td>2048</td><td>FP16+TF32</td><td>194.15 ± 0.99</td></tr>
<tr><td>2048</td><td>FP16_REDUCED</td><td>193.76 ± 0.86</td></tr>
<tr><td>2048</td><td>BF16</td><td>174.12 ± 0.73</td></tr>
<tr><td>2048</td><td>BF16+TF32</td><td>176.25 ± 0.55</td></tr>
<tr><td>4096</td><td>FP32</td><td>18.65 ± 0.06</td></tr>
<tr><td>4096</td><td>FP32+TF32</td><td>120.11 ± 5.62</td></tr>
<tr><td>4096</td><td>FP16</td><td>246.15 ± 0.27</td></tr>
<tr><td>4096</td><td>FP16+TF32</td><td>245.20 ± 0.30</td></tr>
<tr><td>4096</td><td>FP16_REDUCED</td><td>245.46 ± 0.34</td></tr>
<tr><td>4096</td><td>BF16</td><td>249.14 ± 0.32</td></tr>
<tr><td>4096</td><td>BF16+TF32</td><td>249.27 ± 0.31</td></tr>
<tr><td>8192</td><td>FP32</td><td>17.35 ± 1.68</td></tr>
<tr><td>8192</td><td>FP32+TF32</td><td>121.59 ± 2.78</td></tr>
<tr><td>8192</td><td>FP16</td><td>234.64 ± 0.82</td></tr>
<tr><td>8192</td><td>FP16+TF32</td><td>232.71 ± 0.46</td></tr>
<tr><td>8192</td><td>FP16_REDUCED</td><td>233.38 ± 0.42</td></tr>
<tr><td>8192</td><td>BF16</td><td>237.60 ± 0.46</td></tr>
<tr><td>8192</td><td>BF16+TF32</td><td>244.52 ± 1.93</td></tr>
</tbody>
</table>

</details>
